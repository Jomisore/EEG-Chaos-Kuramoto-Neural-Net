{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fbe28d-4457-4e27-a1f8-42054d3128ee",
   "metadata": {},
   "source": [
    "# Transfer Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768493e-e6d9-4597-b1ee-7ed21ce6fed9",
   "metadata": {},
   "source": [
    "### Hemispheric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9346d482-d77e-4dc2-ba87-2c4402c38eee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer Entropy from Left to Right (2D embeddings): 0.5814364131726154\n",
      "Transfer Entropy from Right to Left (2D embeddings): 0.5016624825390452\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from pyinform import transfer_entropy\n",
    "\n",
    "# Path to the zipped 2D embedded data\n",
    "zip_file_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/2dembedded_data.zip'\n",
    "extraction_dir = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/temp_extraction'\n",
    "\n",
    "embedding_data_list_2D = []\n",
    "\n",
    "# Extract zipped data to a temporary directory\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zipf:\n",
    "    zipf.extractall(extraction_dir)\n",
    "\n",
    "eeg_channels = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6',\n",
    "                'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6',\n",
    "                'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
    "\n",
    "for channel in eeg_channels:\n",
    "    file_path = os.path.join(extraction_dir, f'2dembedded_{channel}_data.npy')\n",
    "    embedding_data = np.load(file_path)\n",
    "    embedding_data_list_2D.append(embedding_data)\n",
    "\n",
    "\n",
    "# Set the desired length\n",
    "desired_length = 4227688\n",
    "\n",
    "# Trim each array in embedding_data_list_2D to desired_length\n",
    "embedding_data_list_2D_trimmed = [data[:desired_length] for data in embedding_data_list_2D]\n",
    "\n",
    "left_channels = ['Fp1', 'F7', 'F3', 'FC5', 'M1', 'T7', 'C3', 'CP5', 'P7', 'P3', 'O1']\n",
    "right_channels = ['Fp2', 'F8', 'F4', 'FC6', 'M2', 'T8', 'C4', 'CP6', 'P8', 'P4', 'O2']\n",
    "central_channels = ['Fpz', 'Fz', 'FC1', 'FC2', 'Cz', 'CP1', 'CP2', 'Pz', 'POz', 'Oz']\n",
    "\n",
    "# Cleanup: Optionally remove the extraction directory after loading the data\n",
    "# shutil.rmtree(extraction_dir) \n",
    "\n",
    "# Group channels by hemisphere\n",
    "left_indices = [eeg_channels.index(ch) for ch in left_channels]\n",
    "right_indices = [eeg_channels.index(ch) for ch in right_channels]\n",
    "\n",
    "# Use one of the dimensions (e.g., x-coordinate) for Transfer Entropy calculation\n",
    "left_data = left_embedding_avg[:, 0]\n",
    "right_data = right_embedding_avg[:, 0]\n",
    "\n",
    "def bin_data(data, num_bins):\n",
    "    hist, bins = np.histogram(data, bins=num_bins)\n",
    "    binned_data = np.digitize(data, bins[:-1]) - 1  # subtract 1 to start binning from 0\n",
    "    return binned_data\n",
    "\n",
    "left_data_binned = bin_data(left_data, 1000)\n",
    "right_data_binned = bin_data(right_data, 1000)\n",
    "\n",
    "# Compute Transfer Entropy\n",
    "k, l = 1, 1\n",
    "try:\n",
    "    TE_left_to_right = transfer_entropy(left_data_binned, right_data_binned, k)\n",
    "    TE_right_to_left = transfer_entropy(right_data_binned, left_data_binned, k)\n",
    "\n",
    "    print(f\"Transfer Entropy from Left to Right (2D embeddings): {TE_left_to_right}\")\n",
    "    print(f\"Transfer Entropy from Right to Left (2D embeddings): {TE_right_to_left}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error computing Transfer Entropy: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5562f44a-2d28-48c3-8736-939618be582b",
   "metadata": {},
   "source": [
    "### Regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32dcf261-708d-4f2e-a1a7-ce904a188f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer Entropy from Frontal to Temporal (2D embeddings): 0.25110661733698914\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from pyinform import transfer_entropy\n",
    "\n",
    "# Path to the zipped 2D embedded data\n",
    "zip_file_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/2dembedded_data.zip'\n",
    "extraction_dir = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/temp_extraction'\n",
    "\n",
    "embedding_data_list_2D = []\n",
    "\n",
    "# Extract zipped data to a temporary directory\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zipf:\n",
    "    zipf.extractall(extraction_dir)\n",
    "\n",
    "eeg_channels = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6',\n",
    "                'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6',\n",
    "                'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
    "\n",
    "for channel in eeg_channels:\n",
    "    file_path = os.path.join(extraction_dir, f'2dembedded_{channel}_data.npy')\n",
    "    embedding_data = np.load(file_path)\n",
    "    embedding_data_list_2D.append(embedding_data)\n",
    "\n",
    "desired_length = 4227688\n",
    "embedding_data_list_2D_trimmed = [data[:desired_length] for data in embedding_data_list_2D]\n",
    "\n",
    "# Brain regions\n",
    "frontal_channels = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8']\n",
    "temporal_channels = ['T7', 'T8']\n",
    "parietal_channels = ['CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8']\n",
    "occipital_channels = ['O1', 'Oz', 'O2']\n",
    "\n",
    "frontal_indices = [eeg_channels.index(ch) for ch in frontal_channels]\n",
    "temporal_indices = [eeg_channels.index(ch) for ch in temporal_channels]\n",
    "parietal_indices = [eeg_channels.index(ch) for ch in parietal_channels]\n",
    "occipital_indices = [eeg_channels.index(ch) for ch in occipital_channels]\n",
    "\n",
    "# Getting average for each region\n",
    "frontal_data_avg = np.mean([embedding_data_list_2D_trimmed[i] for i in frontal_indices], axis=0)\n",
    "temporal_data_avg = np.mean([embedding_data_list_2D_trimmed[i] for i in temporal_indices], axis=0)\n",
    "parietal_data_avg = np.mean([embedding_data_list_2D_trimmed[i] for i in parietal_indices], axis=0)\n",
    "occipital_data_avg = np.mean([embedding_data_list_2D_trimmed[i] for i in occipital_indices], axis=0)\n",
    "\n",
    "# Use one of the dimensions for Transfer Entropy calculation\n",
    "frontal_data = frontal_data_avg[:, 0]\n",
    "temporal_data = temporal_data_avg[:, 0]\n",
    "parietal_data = parietal_data_avg[:, 0]\n",
    "occipital_data = occipital_data_avg[:, 0]\n",
    "\n",
    "def bin_data(data, num_bins):\n",
    "    hist, bins = np.histogram(data, bins=num_bins)\n",
    "    binned_data = np.digitize(data, bins[:-1]) - 1\n",
    "    return binned_data\n",
    "\n",
    "frontal_data_binned = bin_data(frontal_data, 1000)\n",
    "temporal_data_binned = bin_data(temporal_data, 1000)\n",
    "parietal_data_binned = bin_data(parietal_data, 1000)\n",
    "occipital_data_binned = bin_data(occipital_data, 1000)\n",
    "\n",
    "# Example: Compute Transfer Entropy from Frontal to Temporal\n",
    "k, l = 1, 1\n",
    "try:\n",
    "    TE_frontal_to_temporal = transfer_entropy(frontal_data_binned, temporal_data_binned, k)\n",
    "    print(f\"Transfer Entropy from Frontal to Temporal (2D embeddings): {TE_frontal_to_temporal}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error computing Transfer Entropy: {e}\")\n",
    "\n",
    "# Cleanup: Optionally remove the extraction directory after loading the data\n",
    "# shutil.rmtree(extraction_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45709a-aa4c-4f1f-a5df-f0375c46c62e",
   "metadata": {},
   "source": [
    "### Full Granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d601414-db65-4f2b-ae89-34c632322a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from pyinform import transfer_entropy\n",
    "\n",
    "# Path to the zipped 2D embedded data\n",
    "zip_file_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/2dembedded_data.zip'\n",
    "extraction_dir = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/temp_extraction'\n",
    "\n",
    "embedding_data_list_2D = []\n",
    "\n",
    "# Extract zipped data to a temporary directory\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zipf:\n",
    "    zipf.extractall(extraction_dir)\n",
    "\n",
    "eeg_channels = [...]  # same as provided\n",
    "\n",
    "for channel in eeg_channels:\n",
    "    file_path = os.path.join(extraction_dir, f'2dembedded_{channel}_data.npy')\n",
    "    embedding_data = np.load(file_path)\n",
    "    embedding_data_list_2D.append(embedding_data)\n",
    "\n",
    "desired_length = 4227688\n",
    "embedding_data_list_2D_trimmed = [data[:desired_length, 0] for data in embedding_data_list_2D]  # only taking one dimension\n",
    "\n",
    "def bin_data(data, num_bins):\n",
    "    hist, bins = np.histogram(data, bins=num_bins)\n",
    "    binned_data = np.digitize(data, bins[:-1]) - 1  # subtract 1 to start binning from 0\n",
    "    return binned_data\n",
    "\n",
    "# Bin all the data\n",
    "embedding_data_list_2D_binned = [bin_data(data, 1000) for data in embedding_data_list_2D_trimmed]\n",
    "\n",
    "# Compute Transfer Entropy for all pairs\n",
    "k = 1\n",
    "for i, source_channel in enumerate(eeg_channels):\n",
    "    for j, target_channel in enumerate(eeg_channels):\n",
    "        if i != j:  # To avoid computing Transfer Entropy for the same channel\n",
    "            try:\n",
    "                TE = transfer_entropy(embedding_data_list_2D_binned[i], embedding_data_list_2D_binned[j], k)\n",
    "                print(f\"Transfer Entropy from {source_channel} to {target_channel}: {TE}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing Transfer Entropy from {source_channel} to {target_channel}: {e}\")\n",
    "\n",
    "# Cleanup: Optionally remove the extraction directory after loading the data\n",
    "# shutil.rmtree(extraction_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d45dd3-633f-495e-91ff-bd04aa9f3c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce2e49-53a3-4f71-84f1-715d14557b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_randomize(ts):\n",
    "    ts_randomized = np.empty_like(ts)\n",
    "    for i in range(ts.shape[0]):\n",
    "        # Fourier transform\n",
    "        ts_fourier = np.fft.rfft(ts[i])\n",
    "\n",
    "        # Generate random phases\n",
    "        random_phases = np.exp(1j * np.random.uniform(0, 2*np.pi, len(ts[i]) // 2 + 1))\n",
    "\n",
    "        # Apply the random phases to the Fourier transform\n",
    "        ts_fourier_randomized = ts_fourier * random_phases\n",
    "\n",
    "        # Inverse Fourier transform\n",
    "        ts_randomized[i] = np.fft.irfft(ts_fourier_randomized, len(ts[i]))\n",
    "        \n",
    "    return ts_randomized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
