{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2eaa1c-da0f-4b5f-956c-fd60ced43eb2",
   "metadata": {},
   "source": [
    "# PyCoBi Bifurcation with Auto-07p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0e8565-e95f-48a5-96fd-7611ee4138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nolds\n",
    "import scipy.io\n",
    "import mne\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyqtgraph as pg\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import antropy as ent\n",
    "from antropy import higuchi_fd\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.computation import RQAComputation\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.result import RQAResult\n",
    "from pyrqa.opencl import OpenCL\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.image_generator import ImageGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from antropy import higuchi_fd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6737d2-40be-4dc5-942f-45b9df6e7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Spectral Analysis\"\n",
    "\n",
    "BandPower_x = np.load(os.path.join(directory_path, \"BandPower_x.npy\"), allow_pickle=True)\n",
    "FastFourierTransform_x = np.load(os.path.join(directory_path, \"FastFourierTransform_x.npy\"), allow_pickle=True)\n",
    "LombScarglePeriodogram_x = np.load(os.path.join(directory_path, \"LombScarglePeriodogram_x.npy\"), allow_pickle=True)\n",
    "PeakFrequencies_x = np.load(os.path.join(directory_path, \"PeakFrequencies_x.npy\"), allow_pickle=True)\n",
    "ShortTimeFourier_x = np.load(os.path.join(directory_path, \"ShortTimeFourier_x.npy\"), allow_pickle=True)\n",
    "SpectralCentroids_x = np.load(os.path.join(directory_path, \"SpectralCentroids_x.npy\"), allow_pickle=True)\n",
    "SpectralEdgeDensities_x = np.load(os.path.join(directory_path, \"SpectralEdgeDensities_x.npy\"), allow_pickle=True)\n",
    "spectral_entropy_x = np.load(os.path.join(directory_path, \"spectral_entropy_x.npy\"), allow_pickle=True)\n",
    "wavelet_x = np.load(os.path.join(directory_path, \"wavelet_x.npy\"), allow_pickle=True)\n",
    "welchs_x = np.load(os.path.join(directory_path, \"welchs_x.npy\"), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61903f4-ce21-4f94-be9f-f3c6643560fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Fp1           Fpz           Fp2           F7         F3  \\\n",
      "0 -21295.988649 -20109.716727 -24153.383752  3189.340060 -45.189275   \n",
      "1 -21303.747077 -20120.746154 -24163.864012  3178.880909 -56.702035   \n",
      "2 -21315.466571 -20130.126577 -24171.944343  3164.903807 -69.465350   \n",
      "3 -21317.809594 -20131.044726 -24174.790986  3159.478572 -73.214591   \n",
      "4 -21325.798142 -20137.522181 -24179.985166  3144.934679 -84.871628   \n",
      "\n",
      "            Fz          F4           F8          FC5          FC1  ...  \\\n",
      "0 -8525.066680 -642.128590  3487.913621  6324.956639  6503.012177  ...   \n",
      "1 -8532.499649 -651.966372  3477.011771  6315.078704  6496.522520  ...   \n",
      "2 -8544.315275 -663.772856  3463.194795  6302.391524  6483.178723  ...   \n",
      "3 -8545.873916 -666.109249  3457.870782  6297.212341  6481.970244  ...   \n",
      "4 -8551.164448 -671.761501  3450.466406  6283.925509  6477.045614  ...   \n",
      "\n",
      "            P7           P3          Pz           P4           P8  \\\n",
      "0  3374.048029 -3617.197964 -611.584742 -1667.222644  7523.612085   \n",
      "1  3372.073657 -3621.118134 -617.022909 -1673.653480  7516.945510   \n",
      "2  3363.104066 -3632.122011 -627.957966 -1684.569981  7502.158816   \n",
      "3  3354.943617 -3639.476353 -633.425118 -1690.436299  7496.978015   \n",
      "4  3343.913673 -3645.950907 -639.939845 -1695.157414  7491.664259   \n",
      "\n",
      "           POz           O1           Oz           O2  Time  \n",
      "0 -9446.685389 -6091.788931 -1392.835634  3559.608191   0.0  \n",
      "1 -9451.045628 -6094.343708 -1395.070231  3556.367972   1.0  \n",
      "2 -9460.798474 -6104.626002 -1406.149675  3543.184223   2.0  \n",
      "3 -9468.273627 -6110.845490 -1413.911429  3536.078117   3.0  \n",
      "4 -9477.076964 -6117.640828 -1419.832213  3529.343349   4.0  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths\n",
    "base_dir = '/home/vincent/AAA_projects/MVCS/Neuroscience/DataFrames/' \n",
    "eeg_df_path = base_dir + 'eeg_df.csv'\n",
    "\n",
    "# load data\n",
    "eeg_df = pd.read_csv(eeg_df_path)\n",
    "\n",
    "print(eeg_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74627d7-d406-4570-aa56-eba17b9ed84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wilson-Cowan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7998f953-4b19-4b0e-a374-4d0ecdc45801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3462: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial condition for E(0): Fp1    -2.019481e+04\n",
      "Fpz    -1.837152e+04\n",
      "Fp2    -1.944451e+04\n",
      "F7      1.842709e+03\n",
      "F3     -2.443234e+02\n",
      "Fz     -8.513399e+03\n",
      "F4     -4.225759e+02\n",
      "F8      4.559767e+03\n",
      "FC5     6.697618e+03\n",
      "FC1     7.492128e+03\n",
      "FC2    -2.485212e+03\n",
      "FC6     1.135458e+04\n",
      "M1      2.651776e+02\n",
      "T7     -7.467175e+03\n",
      "C3     -1.408262e+03\n",
      "Cz      3.137791e+03\n",
      "C4      6.958163e+03\n",
      "T8      2.392510e+03\n",
      "M2     -8.349746e+03\n",
      "CP5     1.576696e+03\n",
      "CP1    -6.745014e+03\n",
      "CP2     1.450383e+03\n",
      "CP6     5.722390e+03\n",
      "P7      4.161197e+03\n",
      "P3     -3.961754e+03\n",
      "Pz     -3.921798e+02\n",
      "P4     -2.641259e+03\n",
      "P8      9.034929e+03\n",
      "POz    -1.156767e+04\n",
      "O1     -1.129762e+04\n",
      "Oz     -1.384648e+03\n",
      "O2      3.931208e+03\n",
      "Time    2.113894e+06\n",
      "dtype: float64\n",
      "Initial condition for I(0): Fp1     1.738809e+03\n",
      "Fpz     1.381171e+03\n",
      "Fp2     2.896979e+03\n",
      "F7      5.748693e+03\n",
      "F3      2.074885e+03\n",
      "Fz      1.532398e+03\n",
      "F4      5.396281e+02\n",
      "F8      1.216357e+03\n",
      "FC5     4.303830e+03\n",
      "FC1     1.645656e+03\n",
      "FC2     5.178472e+02\n",
      "FC6     9.250857e+02\n",
      "M1      1.208784e+03\n",
      "T7      1.727197e+03\n",
      "C3      1.774195e+03\n",
      "Cz      3.997481e+02\n",
      "C4      1.268278e+03\n",
      "T8      8.954828e+02\n",
      "M2      6.019935e+02\n",
      "CP5     2.535496e+03\n",
      "CP1     1.097760e+03\n",
      "CP2     7.252363e+02\n",
      "CP6     1.448686e+03\n",
      "P7      7.477227e+02\n",
      "P3      4.585712e+02\n",
      "Pz      2.381715e+02\n",
      "P4      7.544098e+02\n",
      "P8      9.885521e+02\n",
      "POz     1.161552e+03\n",
      "O1      1.620809e+03\n",
      "Oz      3.794670e+02\n",
      "O2      4.432245e+02\n",
      "Time    1.220457e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics for initial conditions\n",
    "E_init = np.mean(eeg_df)\n",
    "I_init = np.std(eeg_df)\n",
    "\n",
    "print(f\"Initial condition for E(0): {E_init}\")\n",
    "print(f\"Initial condition for I(0): {I_init}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8c1cd-e326-4deb-a3fc-51db7465e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "Assumptive Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20660324-4ce6-40ab-9f6f-79708f46cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    \n",
    "    # Handle division by zero and NaN values\n",
    "    if arr_max - arr_min == 0:\n",
    "        return np.zeros_like(arr)  # Return zeros array\n",
    "    else:\n",
    "        return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "# Load the data for BandPower_x\n",
    "with open(os.path.join('/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Spectral Analysis', \"BandPower_x.npy\"), 'rb') as f:\n",
    "    band_power_dict = np.load(f, allow_pickle=True).item()\n",
    "\n",
    "# Normalize each band power entry in the dictionary\n",
    "for key in band_power_dict:\n",
    "    band_power_dict[key] = normalize(band_power_dict[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62eba021-c4fb-4a43-80df-07254dbeb94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.04757563641953081\n",
      "0.7114263594872726\n"
     ]
    }
   ],
   "source": [
    "# Load the data function\n",
    "def load_data(file_name):\n",
    "    with open(os.path.join('/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Spectral Analysis', file_name), 'rb') as f:\n",
    "        data = np.load(f, allow_pickle=True)\n",
    "        if data.shape == ():  # check if it is a 0-dimensional array (which might contain a dictionary)\n",
    "            return data.item()\n",
    "        else:\n",
    "            return {\"data_array\": data}\n",
    "\n",
    "# Normalize function for dictionary\n",
    "def normalize_dict(d):\n",
    "    for key in d:\n",
    "        d[key] = normalize(d[key])\n",
    "    return d\n",
    "\n",
    "# Normalize function for numpy array\n",
    "def normalize(arr):\n",
    "    arr_min = np.min(arr)\n",
    "    arr_max = np.max(arr)\n",
    "    if arr_max - arr_min == 0:\n",
    "        return np.zeros_like(arr)\n",
    "    else:\n",
    "        return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "# Load and normalize data\n",
    "BandPower_x = normalize_dict(load_data(\"BandPower_x.npy\"))\n",
    "FastFourierTransform_x = normalize_dict(load_data(\"FastFourierTransform_x.npy\"))\n",
    "PeakFrequencies_x = normalize_dict(load_data(\"PeakFrequencies_x.npy\"))\n",
    "SpectralCentroids_x = normalize_dict(load_data(\"SpectralCentroids_x.npy\"))\n",
    "SpectralEdgeDensities_x = normalize_dict(load_data(\"SpectralEdgeDensities_x.npy\"))\n",
    "spectral_entropy_x = normalize_dict(load_data(\"spectral_entropy_x.npy\"))\n",
    "welchs_x = normalize_dict(load_data(\"welchs_x.npy\"))\n",
    "\n",
    "# Use normalized values to derive E_init and I_init\n",
    "\n",
    "# Assuming these measures indicate excitatory activity\n",
    "E_measure = (\n",
    "    np.mean(list(BandPower_x.values())) +\n",
    "    np.mean(list(FastFourierTransform_x.values())) +\n",
    "    np.mean(list(PeakFrequencies_x.values())) +\n",
    "    np.mean(list(SpectralCentroids_x.values())) +\n",
    "    np.mean(list(SpectralEdgeDensities_x.values())) -\n",
    "    np.mean(list(spectral_entropy_x.values())) +\n",
    "    np.mean(list(welchs_x.values()))\n",
    ") / 7\n",
    "\n",
    "# Assuming spectral entropy indicates inhibitory activity\n",
    "I_measure = np.mean(list(spectral_entropy_x.values()))\n",
    "\n",
    "E_init = E_measure\n",
    "I_init = I_measure\n",
    "\n",
    "print(E_init)\n",
    "print(I_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a821826-d23e-4a15-be81-772a8ba739fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda725c-0f6d-4d9c-92e2-aa8fc24a709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering techniques on EEG data to differentiate regions of high and low activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073b275c-9582-4d95-99f2-375706f0c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys for PeakFrequencies_x: dict_keys(['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'O2'])\n",
      "Keys for FastFourierTransform_x: dict_keys(['data_array'])\n",
      "Keys for SpectralCentroids_x: dict_keys(['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'O2'])\n",
      "Keys for SpectralEdgeDensities_x: dict_keys(['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2', 'Fpz'])\n",
      "Keys for spectral_entropy_x: dict_keys(['data_array'])\n",
      "Keys for welchs_x: dict_keys(['data_array'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys for PeakFrequencies_x:\", PeakFrequencies_x.keys())\n",
    "print(\"Keys for FastFourierTransform_x:\", FastFourierTransform_x.keys())\n",
    "print(\"Keys for SpectralCentroids_x:\", SpectralCentroids_x.keys())\n",
    "print(\"Keys for SpectralEdgeDensities_x:\", SpectralEdgeDensities_x.keys())\n",
    "print(\"Keys for spectral_entropy_x:\", spectral_entropy_x.keys())\n",
    "print(\"Keys for welchs_x:\", welchs_x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34656e3e-4a94-4a13-a694-ad3b0a84c3a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Standardize the features\u001b[39;00m\n\u001b[1;32m     14\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 15\u001b[0m features_standardized \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Determine the optimal number of clusters using silhouette score\u001b[39;00m\n\u001b[1;32m     18\u001b[0m range_n_clusters \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:859\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    860\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 861\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'dict'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume your data is loaded like this:\n",
    "# BandPower_x, FastFourierTransform_x, PeakFrequencies_x, SpectralCentroids_x, SpectralEdgeDensities_x, spectral_entropy_x, welchs_x, mfdfa\n",
    "\n",
    "# Stack the features horizontally\n",
    "features = np.column_stack([FastFourierTransform_x, PeakFrequencies_x, SpectralCentroids_x, SpectralEdgeDensities_x, spectral_entropy_x, welchs_x])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# Determine the optimal number of clusters using silhouette score\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    cluster_labels = kmeans.fit_predict(features_standardized)\n",
    "    silhouette_avg = silhouette_score(features_standardized, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure()\n",
    "plt.bar(range_n_clusters, silhouette_scores)\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.show()\n",
    "\n",
    "# Choose an optimal number of clusters and run k-means clustering\n",
    "optimal_clusters = range_n_clusters[np.argmax(silhouette_scores)]\n",
    "kmeans = KMeans(n_clusters=optimal_clusters)\n",
    "clusters = kmeans.fit_predict(features_standardized)\n",
    "\n",
    "# Visualize the clusters (you can choose any two features for a scatter plot or project them using PCA for visualization)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(features_standardized[:, 0], features_standardized[:, 1], c=clusters, cmap='rainbow')\n",
    "plt.title(\"Clusters\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c081cdc-a097-49e2-a4af-1f8425b1eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Derived Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b24d3-e649-473b-8b26-81ed9a46927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482e285-7449-4917-ae8a-6033b72c3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dipole model or the current source density,  LORETA or sLORETA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5c1a7f-739d-4c36-84dd-9d2d300981c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a PyCoBi object\n",
    "pcb = pycobi()\n",
    "\n",
    "# Use the Hodgkin-Huxley model as your system of ODEs\n",
    "# Assuming the fortran version of the Hodgkin-Huxley model is available in a file named 'hodgkin_huxley.f'\n",
    "pcb.load_equations('put model here.f')\n",
    "\n",
    "# Set the initial conditions and parameters for your system\n",
    "pcb.set_initial_conditions([V_init, 0.05, 0.6, 0.32])\n",
    "\n",
    "# Define your control parameter and its range for the continuation\n",
    "pcb.set_control_parameter('I', start=0, stop=100, step=1)\n",
    "\n",
    "# Run the continuation\n",
    "pcb.run_continuation()\n",
    "\n",
    "# Display the bifurcation diagram\n",
    "pcb.plot_bifurcation_diagram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28c8f8-5009-461f-96c6-fe62c1c913ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccd96e-87db-4d4f-b415-aeb3d954a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model-Based Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea519c5-0fd8-44a7-90da-b2e579e4d6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840456e-fe62-4cb9-935e-e616bf1a1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jansen-Rit model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
