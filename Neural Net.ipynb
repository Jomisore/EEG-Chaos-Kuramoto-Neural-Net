{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "516441f8-ccaa-478a-a7e3-6db52f2a74ef",
   "metadata": {},
   "source": [
    "# Load Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af2a006-4eab-47fa-bf4f-e645f3bdb3ba",
   "metadata": {},
   "source": [
    "gradient clipping, learning rate scheduling, advanced regularization techniques,\n",
    " Bidirectional RNNs, attention mechanisms, transformer architectures, oscillators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b7943e-7c23-49d8-bc4d-d65dfd8c603e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# List of tensor paths\n",
    "tensor_paths = [\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/EEG_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/arnold_tongues_rotation_numbers_tensor.pt\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/bandpowers_embedding_net.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/band_power_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/cnn_dspm_tensor.pt\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/fast_fourier_transform_psd_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/higuchi_fractal_dimensions_tensor.pt\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/Hurst_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/mfdfa_concatd_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/mfdfa_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/short_time_fourier_transform_tensor.pth\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/transfer_entropy_granular_tensor.pt\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/transfer_entropy_hemispheric_avg_input_tensor.pt\",\n",
    "    \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/transfer_entropy_regional_tensor.pt\"\n",
    "]\n",
    "\n",
    "# Load the tensors into a dictionary\n",
    "tensors = {path.split('/')[-1].replace('.pt', ''): torch.load(path) for path in tensor_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43be465b-9c39-4493-9313-db7eef868865",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG_tensorh: torch.Size([1, 4227788, 1, 32])\n",
      "arnold_tongues_rotation_numbers_tensor: torch.Size([32, 300, 300])\n",
      "bandpowers_embedding_neth: state_dict (model parameters)\n",
      "band_power_tensorh: torch.Size([4227788, 32, 5])\n",
      "cnn_dspm_tensor: torch.Size([19, 18840, 10])\n",
      "fast_fourier_transform_psd_tensorh: torch.Size([32, 4227788])\n",
      "higuchi_fractal_dimensions_tensor: torch.Size([1, 1, 4, 8])\n",
      "Hurst_tensorh: torch.Size([1, 1, 32, 1])\n",
      "mfdfa_concatd_tensorh: torch.Size([32, 1, 30, 2])\n",
      "mfdfa_tensorh: torch.Size([9, 32, 10, 1])\n",
      "short_time_fourier_transform_tensorh: torch.Size([32, 1001, 4229])\n",
      "transfer_entropy_granular_tensor: torch.Size([4, 4])\n",
      "transfer_entropy_hemispheric_avg_input_tensor: torch.Size([92, 92])\n",
      "transfer_entropy_regional_tensor: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "# Load each tensor and print its shape\n",
    "tensor_shapes = {}\n",
    "for path in tensor_paths:\n",
    "    tensor_name = path.split(\"/\")[-1].replace(\".pt\", \"\").replace(\".pth\", \"\")\n",
    "    data = torch.load(path)\n",
    "    \n",
    "    # Check if the loaded data is a state dictionary or a tensor\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        tensor_shapes[tensor_name] = data.shape\n",
    "    elif isinstance(data, dict):  # Likely a state_dict\n",
    "        tensor_shapes[tensor_name] = \"state_dict (model parameters)\"\n",
    "    else:\n",
    "        tensor_shapes[tensor_name] = \"unknown type\"\n",
    "\n",
    "# Print the tensor shapes\n",
    "for name, shape in tensor_shapes.items():\n",
    "    print(f\"{name}: {shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc365929-f568-48e7-af9e-aa60e517f841",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff40f7-f03a-43bc-9afb-1ce7afd9f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseEmbeddingNet(nn.Module):\n",
    "    def __init__(self, input_channels, conv_output_channels, height, width):\n",
    "        super(BaseEmbeddingNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, conv_output_channels, 3)\n",
    "        self.batch_norm = nn.BatchNorm2d(conv_output_channels)\n",
    "        self.fc1 = nn.Linear(conv_output_channels * (height - 2) * (width - 2), 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.batch_norm(self.conv1(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        return x\n",
    "\n",
    "class EEGEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self, num_timepoints):\n",
    "        super().__init__(32, 64, num_timepoints, 1)\n",
    "\n",
    "class RotationEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(32, 64, 298, 298)\n",
    "\n",
    "class BandPowerEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(32, 64, 5, 5)\n",
    "\n",
    "class DSPMEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(19, 64, 18840, 10)\n",
    "\n",
    "class FastFourierEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self, new_dim_height, new_dim_width):\n",
    "        super().__init__(32, 64, new_dim_height, new_dim_width)\n",
    "\n",
    "class HiguchiFractalEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(1, 64, 4, 8)\n",
    "\n",
    "class HurstEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(1, 64, 32, 1)\n",
    "\n",
    "class MFDFAConcatdEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(1, 64, 30, 2)\n",
    "\n",
    "class MFDFAEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(32, 64, 10, 1)\n",
    "\n",
    "class ShortTimeFourierEmbeddingNet(BaseEmbeddingNet):\n",
    "    def __init__(self):\n",
    "        super().__init__(1001, 64, 4229, 1)\n",
    "\n",
    "class PairwiseMeasureNet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e9ff8-e3e5-4320-ab8a-396792b54687",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main Network\n",
    "class MainNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Assuming all embedding networks produce a 512 sized vector\n",
    "        # If we have 10 tensors, then 10*512 = 5120\n",
    "        self.fc1 = nn.Linear(5120, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 1) # Assuming binary classification\n",
    "\n",
    "    def forward(self, *args):\n",
    "        # Assuming each tensor is processed through its embedding network\n",
    "        # and then passed in order as arguments to this forward method\n",
    "        concatenated = torch.cat(args, dim=1)\n",
    "        x = self.fc1(concatenated)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2d2b6-15eb-4504-94e6-79201f77fe55",
   "metadata": {},
   "source": [
    "# Spectral Centroid Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3aa38-35d0-4a2f-8816-611676d2ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Convert dictionary values to numpy array\n",
    "spectral_centroids_array = np.array(list(spectral_centroids_data.values()))\n",
    "\n",
    "# Convert numpy array to PyTorch tensor\n",
    "spectral_centroids_tensor = torch.tensor(spectral_centroids_array, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "# Print out the shape to confirm\n",
    "print(spectral_centroids_tensor.shape)  # This should print torch.Size([1, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0f91f-cb9c-4ceb-b846-9073d3d12ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNEEGPredictor(nn.Module):\n",
    "    def __init__(self, num_channels, num_time_points, num_centroids):\n",
    "        super(CNNEEGPredictor, self).__init__()\n",
    "        # Assuming a 1D CNN here for simplicity\n",
    "        self.conv1 = nn.Conv1d(num_channels, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(128 * num_time_points + num_centroids, 256)\n",
    "        self.fc2 = nn.Linear(256, num_time_points)  # Adjust the output size as needed\n",
    "\n",
    "    def forward(self, x, centroids):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the data\n",
    "        x = torch.cat([x, centroids], dim=1)  # Concatenate the flattened data with centroids\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
