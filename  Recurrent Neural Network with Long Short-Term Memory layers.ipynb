{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1dc70d0-cd59-49c7-ae55-cfc6e9c30e28",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network with Long Short-Term Memory layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0736b0cf-1a8e-4728-a81b-52eaae078271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "base_dir = '/home/vincent/AAA_projects/MVCS/Neuroscience/'\n",
    "eeg_df_path = base_dir + 'DataFrames/eeg_df.csv'\n",
    "merged_stim_df_path = base_dir + 'DataFrames/merged_stim_df.csv'\n",
    "hurst_exponents_path = base_dir + 'HurstExponents/hurst_exponents_df.csv'\n",
    "rnn_mfdfa_X_path = base_dir + 'RNN_data/rnn_X_data_combined.npy'\n",
    "kuramoto_phases = '/home/vincent/AAA_projects/MVCS/Neuroscience/kuramoto_phases.npy'\n",
    "\n",
    "# load data\n",
    "eeg_df = pd.read_csv(eeg_df_path)\n",
    "merged_stim_df = pd.read_csv(merged_stim_df_path)\n",
    "hurst_exponents_df = pd.read_csv(hurst_exponents_path)\n",
    "rnn_mfdfa_X_df_combined = np.load(rnn_mfdfa_X_path)\n",
    "kuramoto_phases = np.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6dc6b2-4941-4108-b8e5-3ed94756ba9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fb48fc-3621-4e80-91c3-0c65213e6cb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of eeg_tensor: torch.Size([4227788, 33])\n",
      "Shape of merged_stim_tensor: torch.Size([18, 9])\n",
      "Shape of hurst_exponents_tensor: torch.Size([32, 1])\n",
      "Shape of rnn_X_tensor: torch.Size([860, 100, 51])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the saved PSD data\n",
    "psd_data_dict = np.load(save_path, allow_pickle=True).item()\n",
    "\n",
    "# Convert the PSD values to a 2D array format\n",
    "num_channels = len(eeg_channels)\n",
    "psd_array = np.array([psd_data_dict[channel] for channel in eeg_channels]).T\n",
    "\n",
    "# Normalize the PSD values (Min-Max normalization)\n",
    "psd_array = (psd_array - np.min(psd_array, axis=0)) / (np.max(psd_array, axis=0) - np.min(psd_array, axis=0) + 1e-8)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "psd_tensor = torch.tensor(psd_array, dtype=torch.float32)\n",
    "\n",
    "# Add the feature dimension\n",
    "psd_tensor = psd_tensor.unsqueeze(-1)\n",
    "\n",
    "print(psd_tensor.shape)  # Should print [sequence_length, num_channels, 1]\n",
    "\n",
    "# Check if 'StimType' column is present in the dataframe\n",
    "if 'StimType' in merged_stim_df.columns:\n",
    "    # Proceed with replacement of values and dropping the column\n",
    "    merged_stim_df[\"Frequency\"] = merged_stim_df[\"StimType\"].replace(frequency_mapping)\n",
    "    merged_stim_df[\"Location\"] = merged_stim_df[\"StimType\"].replace(location_mapping)\n",
    "    merged_stim_df.drop('StimType', axis=1, inplace=True)\n",
    "else:\n",
    "    print(\"The 'StimType' column does not exist in the dataframe.\")\n",
    "\n",
    "# Replace \"Stim Start\" with 1 and \"Stim Stop\" with 2\n",
    "merged_stim_df[\"EventDescription\"] = merged_stim_df[\"EventDescription\"].replace({\n",
    "    \"Stim Start\": 1,\n",
    "    \"Stim Stop\": 2\n",
    "})\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "eeg_tensor = torch.tensor(eeg_df.values, dtype=torch.float32)\n",
    "merged_stim_tensor = torch.tensor(merged_stim_df.values, dtype=torch.float32)\n",
    "hurst_exponents_tensor = torch.tensor(hurst_exponents_df.values, dtype=torch.float32)\n",
    "rnn_mfdfa_X_tensor = torch.tensor(rnn_mfdfa_X_df_combined, dtype=torch.float32)\n",
    "kuramoto_tensor = torch.FloatTensor(kuramoto_phases).transpose(0, 1)\n",
    "\n",
    "# Print tensor shapes\n",
    "print(\"Shape of eeg_tensor:\", eeg_tensor.shape)\n",
    "print(\"Shape of merged_stim_tensor:\", merged_stim_tensor.shape)\n",
    "print(\"Shape of hurst_exponents_tensor:\", hurst_exponents_tensor.shape)\n",
    "print(\"Shape of rnn_X_tensor:\", rnn_mfdfa_X_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cea771-d8c5-4981-9e38-f5d4f38d6c36",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69d28715-dcea-481e-925a-6ab1d02bbe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of eeg_tensor_normalized: torch.Size([4227788, 33])\n",
      "Shape of merged_stim_tensor: torch.Size([18, 9])\n",
      "Shape of hurst_exponents_tensor_normalized: torch.Size([32, 1])\n",
      "Shape of rnn_mfdfa_X_tensor: torch.Size([860, 100, 51])\n",
      "Normalized EEG Data:\n",
      "tensor([[5.7522e-01, 5.1448e-01, 1.8268e-01, 6.3061e-01, 7.4618e-01, 6.2734e-01,\n",
      "         7.2461e-01, 5.1302e-01, 6.0971e-01, 4.8493e-01, 6.9506e-01, 4.1021e-01,\n",
      "         4.1003e-01, 5.3116e-01, 4.8551e-01, 5.0756e-01, 2.4764e-01, 4.6979e-01,\n",
      "         9.9777e-01, 4.6894e-01, 6.3074e-01, 9.9253e-01, 2.6509e-01, 4.2655e-01,\n",
      "         3.1056e-01, 2.5602e-01, 9.4031e-01, 4.1962e-01, 9.3565e-01, 9.9806e-01,\n",
      "         6.7768e-01, 5.8537e-01, 0.0000e+00],\n",
      "        [5.7460e-01, 5.1307e-01, 1.8183e-01, 6.3044e-01, 7.4559e-01, 6.2672e-01,\n",
      "         7.2198e-01, 5.1129e-01, 6.0946e-01, 4.8444e-01, 6.9261e-01, 4.0888e-01,\n",
      "         4.0934e-01, 5.3096e-01, 4.8520e-01, 5.0703e-01, 2.4690e-01, 4.6855e-01,\n",
      "         9.9677e-01, 4.6884e-01, 6.3010e-01, 9.8969e-01, 2.6431e-01, 4.2610e-01,\n",
      "         3.0934e-01, 2.5311e-01, 9.3834e-01, 4.1842e-01, 9.3466e-01, 9.9775e-01,\n",
      "         6.7710e-01, 5.8460e-01, 2.3653e-07],\n",
      "        [5.7367e-01, 5.1187e-01, 1.8118e-01, 6.3021e-01, 7.4494e-01, 6.2573e-01,\n",
      "         7.1882e-01, 5.0910e-01, 6.0914e-01, 4.8342e-01, 6.8902e-01, 4.0609e-01,\n",
      "         4.0753e-01, 5.3056e-01, 4.8467e-01, 5.0249e-01, 2.4481e-01, 4.6522e-01,\n",
      "         9.9412e-01, 4.6861e-01, 6.2789e-01, 9.8518e-01, 2.6224e-01, 4.2408e-01,\n",
      "         3.0589e-01, 2.4724e-01, 9.3499e-01, 4.1575e-01, 9.3245e-01, 9.9649e-01,\n",
      "         6.7422e-01, 5.8146e-01, 4.7306e-07],\n",
      "        [5.7348e-01, 5.1175e-01, 1.8095e-01, 6.3012e-01, 7.4474e-01, 6.2560e-01,\n",
      "         7.1820e-01, 5.0826e-01, 6.0901e-01, 4.8332e-01, 6.8738e-01, 4.0552e-01,\n",
      "         4.0665e-01, 5.3043e-01, 4.8451e-01, 5.0118e-01, 2.4349e-01, 4.6403e-01,\n",
      "         9.9214e-01, 4.6839e-01, 6.2692e-01, 9.8370e-01, 2.6162e-01, 4.2223e-01,\n",
      "         3.0358e-01, 2.4431e-01, 9.3319e-01, 4.1481e-01, 9.3076e-01, 9.9573e-01,\n",
      "         6.7220e-01, 5.7977e-01, 7.0959e-07],\n",
      "        [5.7284e-01, 5.1092e-01, 1.8053e-01, 6.2988e-01, 7.4414e-01, 6.2515e-01,\n",
      "         7.1669e-01, 5.0708e-01, 6.0867e-01, 4.8295e-01, 6.8575e-01, 4.0396e-01,\n",
      "         4.0549e-01, 5.3002e-01, 4.8430e-01, 5.0048e-01, 2.4292e-01, 4.6254e-01,\n",
      "         9.9009e-01, 4.6818e-01, 6.2646e-01, 9.8103e-01, 2.6052e-01, 4.1974e-01,\n",
      "         3.0156e-01, 2.4082e-01, 9.3174e-01, 4.1385e-01, 9.2877e-01, 9.9490e-01,\n",
      "         6.7066e-01, 5.7817e-01, 9.4612e-07]])\n",
      "\n",
      "Normalized Hurst Exponents Data:\n",
      "tensor([[0.8321],\n",
      "        [0.4175],\n",
      "        [0.6617],\n",
      "        [0.1171],\n",
      "        [0.2874]])\n",
      "\n",
      "Normalized Merged Stim Data:\n",
      "tensor([[1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 0.0000, 0.0000, 0.0147, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 0.0000, 0.0000, 0.0629, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 0.0000, 0.0000, 0.0775, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 0.0000, 0.0000, 0.1258, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "Normalized RNN MFDFa X Data:\n",
      "tensor([[0.0000e+00, 0.0000e+00, 1.7586e-06, 3.7438e-06, 6.0051e-06, 8.6019e-06,\n",
      "         1.1601e-05, 1.5068e-05, 1.9053e-05, 2.3560e-05, 2.8515e-05, 3.3741e-05,\n",
      "         3.8983e-05, 4.3980e-05, 4.8547e-05, 5.2607e-05, 5.6174e-05, 5.9307e-05,\n",
      "         6.2080e-05, 6.4558e-05, 6.6792e-05, 6.8815e-05, 7.0627e-05, 7.2170e-05,\n",
      "         7.3254e-05, 7.3346e-05, 7.1022e-05, 6.2492e-05, 3.8760e-05, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5732e-06, 7.2081e-06, 1.0551e-05,\n",
      "         1.3570e-05, 1.6238e-05, 1.8532e-05, 2.0447e-05, 2.1987e-05, 2.3172e-05,\n",
      "         2.4031e-05, 2.4606e-05, 2.4945e-05],\n",
      "        [1.0005e-04, 5.2847e-05, 5.6454e-05, 6.0306e-05, 6.4377e-05, 6.8613e-05,\n",
      "         7.2927e-05, 7.7209e-05, 8.1331e-05, 8.5173e-05, 8.8648e-05, 9.1721e-05,\n",
      "         9.4415e-05, 9.6785e-05, 9.8896e-05, 1.0080e-04, 1.0255e-04, 1.0415e-04,\n",
      "         1.0563e-04, 1.0699e-04, 1.0825e-04, 1.0940e-04, 1.1044e-04, 1.1131e-04,\n",
      "         1.1184e-04, 1.1154e-04, 1.0904e-04, 1.0059e-04, 7.7218e-05, 3.9002e-05,\n",
      "         3.7422e-05, 3.5272e-05, 3.3758e-05, 3.2763e-05, 3.2085e-05, 3.1378e-05,\n",
      "         3.0763e-05, 3.0337e-05, 3.0063e-05, 3.3504e-05, 3.7151e-05, 4.0649e-05,\n",
      "         4.3963e-05, 4.7055e-05, 4.9893e-05, 5.2454e-05, 5.4730e-05, 5.6726e-05,\n",
      "         5.8458e-05, 5.9957e-05, 6.1260e-05],\n",
      "        [3.0015e-04, 1.8312e-04, 1.8639e-04, 1.8948e-04, 1.9231e-04, 1.9486e-04,\n",
      "         1.9706e-04, 1.9889e-04, 2.0031e-04, 2.0133e-04, 2.0194e-04, 2.0221e-04,\n",
      "         2.0220e-04, 2.0196e-04, 2.0156e-04, 2.0101e-04, 2.0031e-04, 1.9947e-04,\n",
      "         1.9848e-04, 1.9736e-04, 1.9612e-04, 1.9481e-04, 1.9348e-04, 1.9218e-04,\n",
      "         1.9087e-04, 1.8927e-04, 1.8629e-04, 1.7852e-04, 1.5721e-04, 1.2224e-04,\n",
      "         1.1966e-04, 1.1472e-04, 1.1097e-04, 1.0816e-04, 1.0591e-04, 1.0328e-04,\n",
      "         1.0081e-04, 9.8877e-05, 9.7369e-05, 9.9845e-05, 1.0282e-04, 1.0598e-04,\n",
      "         1.0934e-04, 1.1289e-04, 1.1662e-04, 1.2054e-04, 1.2464e-04, 1.2893e-04,\n",
      "         1.3340e-04, 1.3806e-04, 1.4291e-04],\n",
      "        [5.0025e-04, 2.9495e-04, 2.9767e-04, 3.0007e-04, 3.0211e-04, 3.0378e-04,\n",
      "         3.0504e-04, 3.0588e-04, 3.0625e-04, 3.0616e-04, 3.0562e-04, 3.0464e-04,\n",
      "         3.0328e-04, 3.0157e-04, 2.9956e-04, 2.9726e-04, 2.9467e-04, 2.9178e-04,\n",
      "         2.8862e-04, 2.8524e-04, 2.8170e-04, 2.7812e-04, 2.7464e-04, 2.7145e-04,\n",
      "         2.6872e-04, 2.6648e-04, 2.6408e-04, 2.5867e-04, 2.4196e-04, 2.1364e-04,\n",
      "         2.1312e-04, 2.0739e-04, 2.0244e-04, 1.9818e-04, 1.9432e-04, 1.8951e-04,\n",
      "         1.8485e-04, 1.8107e-04, 1.7793e-04, 1.7894e-04, 1.8057e-04, 1.8252e-04,\n",
      "         1.8477e-04, 1.8735e-04, 1.9027e-04, 1.9353e-04, 1.9714e-04, 2.0110e-04,\n",
      "         2.0539e-04, 2.1003e-04, 2.1498e-04],\n",
      "        [9.0045e-04, 5.0610e-04, 5.0657e-04, 5.0680e-04, 5.0677e-04, 5.0642e-04,\n",
      "         5.0572e-04, 5.0459e-04, 5.0298e-04, 5.0085e-04, 4.9816e-04, 4.9491e-04,\n",
      "         4.9111e-04, 4.8678e-04, 4.8194e-04, 4.7660e-04, 4.7078e-04, 4.6450e-04,\n",
      "         4.5783e-04, 4.5088e-04, 4.4384e-04, 4.3694e-04, 4.3056e-04, 4.2519e-04,\n",
      "         4.2153e-04, 4.2042e-04, 4.2253e-04, 4.2674e-04, 4.2632e-04, 4.2047e-04,\n",
      "         4.3189e-04, 4.2923e-04, 4.2401e-04, 4.1734e-04, 4.1013e-04, 4.0039e-04,\n",
      "         3.9091e-04, 3.8332e-04, 3.7711e-04, 3.7561e-04, 3.7522e-04, 3.7559e-04,\n",
      "         3.7672e-04, 3.7870e-04, 3.8161e-04, 3.8557e-04, 3.9071e-04, 3.9715e-04,\n",
      "         4.0496e-04, 4.1420e-04, 4.2484e-04]])\n",
      "Shape of eeg_tensor_normalized: torch.Size([4227788, 33])\n",
      "Shape of merged_stim_tensor: torch.Size([18, 9])\n",
      "Shape of hurst_exponents_tensor_normalized: torch.Size([32, 1])\n",
      "Shape of rnn_mfdfa_X_tensor_normalized: torch.Size([86000, 51])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize eeg_tensor\n",
    "eeg_scaler = MinMaxScaler()\n",
    "eeg_tensor_np = eeg_scaler.fit_transform(eeg_tensor)\n",
    "eeg_tensor_normalized = torch.tensor(eeg_tensor_np, dtype=torch.float32)\n",
    "\n",
    "# Normalize merged_stim_tensor (excluding Sub# and Session columns)\n",
    "merged_stim_scaler = MinMaxScaler()\n",
    "merged_stim_tensor_np = merged_stim_scaler.fit_transform(merged_stim_tensor[:, 2:])\n",
    "merged_stim_tensor[:, 2:] = torch.tensor(merged_stim_tensor_np, dtype=torch.float32)\n",
    "\n",
    "# Normalize hurst_exponents_tensor\n",
    "hurst_scaler = MinMaxScaler()\n",
    "hurst_exponents_tensor_np = hurst_scaler.fit_transform(hurst_exponents_tensor)\n",
    "hurst_exponents_tensor_normalized = torch.tensor(hurst_exponents_tensor_np, dtype=torch.float32)\n",
    "\n",
    "# Normalize rnn_mfdfa_X_tensor\n",
    "rnn_mfdfa_scaler = MinMaxScaler()\n",
    "rnn_mfdfa_X_tensor_reshaped = rnn_mfdfa_X_tensor.view(-1, rnn_mfdfa_X_tensor.size(2))\n",
    "rnn_mfdfa_X_tensor_np = rnn_mfdfa_scaler.fit_transform(rnn_mfdfa_X_tensor_reshaped)\n",
    "rnn_mfdfa_X_tensor_normalized = torch.tensor(rnn_mfdfa_X_tensor_np, dtype=torch.float32)\n",
    "\n",
    "# Print tensor shapes after normalization\n",
    "print(\"Shape of eeg_tensor_normalized:\", eeg_tensor_normalized.shape)\n",
    "print(\"Shape of merged_stim_tensor:\", merged_stim_tensor.shape)\n",
    "print(\"Shape of hurst_exponents_tensor_normalized:\", hurst_exponents_tensor_normalized.shape)\n",
    "print(\"Shape of rnn_mfdfa_X_tensor:\", rnn_mfdfa_X_tensor.shape)\n",
    "\n",
    "# Print the first few rows of each normalized DataFrame\n",
    "print(\"Normalized EEG Data:\")\n",
    "print(eeg_tensor_normalized[:5])  # Print first 5 rows of eeg_tensor_normalized\n",
    "\n",
    "print(\"\\nNormalized Hurst Exponents Data:\")\n",
    "print(hurst_exponents_tensor_normalized[:5])  # Print first 5 rows of hurst_exponents_tensor_normalized\n",
    "\n",
    "print(\"\\nNormalized Merged Stim Data:\")\n",
    "print(merged_stim_tensor[:5])  # Print first 5 rows of merged_stim_tensor\n",
    "\n",
    "print(\"Normalized RNN MFDFa X Data:\")\n",
    "print(rnn_mfdfa_X_tensor_normalized[:5])\n",
    "\n",
    "\n",
    "# Print tensor shapes after normalization\n",
    "print(\"Shape of eeg_tensor_normalized:\", eeg_tensor_normalized.shape)\n",
    "print(\"Shape of merged_stim_tensor:\", merged_stim_tensor.shape)\n",
    "print(\"Shape of hurst_exponents_tensor_normalized:\", hurst_exponents_tensor_normalized.shape)\n",
    "print(\"Shape of rnn_mfdfa_X_tensor_normalized:\", rnn_mfdfa_X_tensor_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f85fc3-9a3f-4c80-8055-783fe6b07b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(tensor, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(tensor) - seq_length - 1):  # -1 to avoid index out of range for y\n",
    "        x = tensor[i:i+seq_length]\n",
    "        y = tensor[i+seq_length]  # the next one is the target\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "seq_length = 50  # you can adjust this\n",
    "X, y = create_sequences(eeg_tensor_normalized, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09cf2f0f-20ba-4661-aaae-dbef59531103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 688 samples\n",
      "Test set: 172 samples\n"
     ]
    }
   ],
   "source": [
    "# Calculate the index separating the training and test data\n",
    "train_test_split_idx = int(len(rnn_mfdfa_X_tensor) * 0.8)\n",
    "\n",
    "# Split rnn_X_tensor, eeg_tensor_normalized and hurst_exponents_tensor_normalized\n",
    "train_X = rnn_mfdfa_X_tensor[:train_test_split_idx]\n",
    "test_X = rnn_mfdfa_X_tensor[train_test_split_idx:]\n",
    "\n",
    "train_X_hurst = hurst_exponents_tensor_normalized[:train_test_split_idx]\n",
    "test_X_hurst = hurst_exponents_tensor_normalized[train_test_split_idx:]\n",
    "\n",
    "train_y = eeg_tensor_normalized[:train_test_split_idx]\n",
    "test_y = eeg_tensor_normalized[train_test_split_idx:]\n",
    "\n",
    "print(f\"Training set: {len(train_X)} samples\")\n",
    "print(f\"Test set: {len(test_X)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd24a696-6518-4027-b0cd-3bf98ca7a597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([688, 100, 51])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([688, 33])\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_X_hurst.shape)\n",
    "print(train_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d25d5cc-c61a-4a10-a03d-dd7806c9dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EEGPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EEGPredictor, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "input_size = train_X.shape[-1]  # input feature dimension\n",
    "hidden_size = 64  # number of hidden units in LSTM\n",
    "output_size = train_y.shape[-1]  # output feature dimension\n",
    "model = EEGPredictor(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06590a77-5ef8-4532-9897-ba399862ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-04 16:07:52,232] A new study created in memory with name: no-name-4a47711b-1093-4ef4-ad7b-27a00e5ce470\n",
      "/tmp/ipykernel_83196/2826018788.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate=trial.suggest_loguniform('learning_rate', 1e-5, 1e-1))\n",
      "[W 2023-08-04 16:07:52,235] Trial 0 failed with parameters: {'hidden_dim': 64, 'layer_dim': 2, 'learning_rate': 0.003371799594331998} because of the following error: AssertionError('Size mismatch between tensors').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vincent/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_83196/2826018788.py\", line 53, in train_model\n",
      "    train_dataset = TensorDataset(train_X, train_X_hurst, train_y)\n",
      "  File \"/home/vincent/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py\", line 189, in __init__\n",
      "    assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors), \"Size mismatch between tensors\"\n",
      "AssertionError: Size mismatch between tensors\n",
      "[W 2023-08-04 16:07:52,236] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Size mismatch between tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83196/2826018788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of finished trials: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_83196/2826018788.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Create TensorDatasets for training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X_hurst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X_hurst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Size mismatch between tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set the precision to 'high'\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "# Make sure your process_dataframes function is returning correctly shaped and combined tensors\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, learning_rate):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # Replace nn.RNN with nn.LSTM\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().cuda()\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().cuda()\n",
    "        h0 = h0.detach()\n",
    "        c0 = c0.detach()\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self(x)\n",
    "        loss = nn.MSELoss()(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "def train_model(trial):\n",
    "    # Define model\n",
    "    model = LSTMModel(input_dim=10,  # adjust this to fit your data\n",
    "                      hidden_dim=trial.suggest_categorical('hidden_dim', [32, 64, 128]),\n",
    "                      layer_dim=trial.suggest_categorical('layer_dim', [2, 3, 4]),\n",
    "                      output_dim=1,  # adjust this to fit your data\n",
    "                      learning_rate=trial.suggest_loguniform('learning_rate', 1e-5, 1e-1))\n",
    "\n",
    "    # Create TensorDatasets for training and test sets\n",
    "    train_dataset = TensorDataset(train_X, train_X_hurst, train_y)\n",
    "    test_dataset = TensorDataset(test_X, test_X_hurst, test_y)\n",
    "    \n",
    "    # If you want to use DataLoader for batching and shuffling during training, you can do the following:\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # Create the Trainer\n",
    "    trainer = pl.Trainer(\n",
    "        devices=2,  # change this according to your setup\n",
    "        accelerator=\"cuda\",  # change this according to your setup\n",
    "        max_epochs=100\n",
    "    )\n",
    "\n",
    "\n",
    "    # Fit the model\n",
    "    trainer.fit(model, train_dl)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mse = 0\n",
    "        loss = nn.MSELoss()\n",
    "        for x, y in train_dl:\n",
    "            mse += loss(model(x), y)\n",
    "        mse /= len(train_dl)\n",
    "\n",
    "    return mse.item()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(train_model, n_trials=100)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0309a-3060-4604-80b9-38428d5d1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move tensors to GPU\n",
    "test_X = test_X.cuda()\n",
    "test_y = test_y.cuda()\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No gradient calculation needed\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    predictions = model(test_X)\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(predictions, test_y)\n",
    "\n",
    "print(f\"Test Loss: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
