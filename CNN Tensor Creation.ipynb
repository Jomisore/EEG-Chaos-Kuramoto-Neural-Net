{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47577a3-7950-4802-8e10-4a9070219477",
   "metadata": {},
   "source": [
    "# CNN Tensor Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89022a6f-8fd5-40d4-9717-abc171c2ff39",
   "metadata": {},
   "source": [
    "# EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f6c2ca6-3d91-4312-9dbf-7a80e1ef5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the EEG data\n",
    "scaler = StandardScaler()\n",
    "EEG_data_standardized = scaler.fit_transform(EEG_data)\n",
    "\n",
    "# Convert the data to a PyTorch tensor\n",
    "eeg_tensor = torch.tensor(EEG_data_standardized, dtype=torch.float32)\n",
    "\n",
    "# Reshape the tensor to: [batch_size, channels, height, width]\n",
    "# Since this is just one EEG dataset, batch size will be 1.\n",
    "# For EEG data, you can think of each channel as an \"image\" where the \"height\" is 1 and the \"width\" is the number of timepoints.\n",
    "eeg_tensor = eeg_tensor.unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "# Saving path for the CNN tensor\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/EEG_tensor.pth\"\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(eeg_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903c557-272d-42c1-b9fe-198f2ff67de8",
   "metadata": {},
   "source": [
    "# Band Powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a0eeaf-ecef-4202-a8f0-9aa431d39072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populated keys in band_powers_data: ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the band powers data from the .npy file\n",
    "band_powers_data = np.load('/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Spectral Analysis/BandPowers_x.npy', allow_pickle=True).item()\n",
    "\n",
    "# Print the populated keys in band_powers_data (channels)\n",
    "print(\"Populated keys in band_powers_data:\", list(band_powers_data.keys()))\n",
    "\n",
    "# Extract eeg_channels from the data (assuming they're the top-level keys)\n",
    "eeg_channels = list(band_powers_data.keys())\n",
    "\n",
    "# Extract frequency_bands from the data (assuming they're the second-level keys for any channel)\n",
    "frequency_bands = list(next(iter(band_powers_data.values())).keys())\n",
    "\n",
    "# Assuming band_powers_data is in the format {channel: {band: values}}\n",
    "# Convert the band powers dictionary to a tensor\n",
    "num_time_steps = len(next(iter(next(iter(band_powers_data.values())).values())))\n",
    "tensor_shape = (num_time_steps, len(eeg_channels), len(frequency_bands))\n",
    "band_power_tensor = torch.empty(tensor_shape)\n",
    "\n",
    "for i, channel in enumerate(eeg_channels):\n",
    "    for j, band in enumerate(frequency_bands):\n",
    "        band_power_tensor[:, i, j] = torch.tensor(band_powers_data[channel][band])\n",
    "\n",
    "# Saving path for the band power tensor\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/band_power_tensor.pth\"\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(band_power_tensor, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c45e5-8802-4f16-bd7d-17022d8d72b1",
   "metadata": {},
   "source": [
    "# Fast Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2be61994-bc65-45ca-979b-524dcf419826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import torch\n",
    "\n",
    "# Load the FFT PSD data\n",
    "load_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Spectral Analysis/combined_fft_psd_x.npy'\n",
    "combined_fft_psd_data = np.load(load_path, allow_pickle=True).item()\n",
    "\n",
    "eeg_channels = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6',\n",
    "                'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6',\n",
    "                'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
    "\n",
    "num_channels = len(combined_fft_psd_data.keys())\n",
    "# Assuming all PSD sequences have the same length\n",
    "num_frequencies = len(next(iter(combined_fft_psd_data.values())))\n",
    "# Reshape the data\n",
    "fft_psd_tensor = torch.empty((num_channels, num_frequencies))\n",
    "\n",
    "for i, channel in enumerate(eeg_channels):\n",
    "    fft_psd_tensor[i] = torch.tensor(combined_fft_psd_data[channel])\n",
    "    \n",
    "# Saving path for the CNN tensor\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/fast_fourier_transform_psd_tensor.pth\"\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(fft_psd_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc54aea-8394-4569-84e5-78b4b3620aae",
   "metadata": {},
   "source": [
    "# Short Time Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6404f8d-8d7f-42d5-a35b-1dc4c62e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the STFT data\n",
    "stft_data_dict = np.load('/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Spectral Analysis/STFT_x.npy', allow_pickle=True).item()\n",
    "\n",
    "# Get number of channels, frequencies, and time intervals from the data\n",
    "num_channels = len(stft_data_dict)\n",
    "num_frequencies, num_time_intervals = stft_data_dict[next(iter(stft_data_dict.keys()))].shape\n",
    "\n",
    "# Initialize a tensor to store the STFT data\n",
    "stft_tensor = torch.empty((num_channels, num_frequencies, num_time_intervals))\n",
    "\n",
    "# Populate the tensor\n",
    "for i, channel_data in enumerate(stft_data_dict.values()):\n",
    "    stft_tensor[i] = torch.tensor(channel_data)\n",
    "\n",
    "# Saving path for the CNN tensor\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/short_time_fourier_transform_tensor.pth\"\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(stft_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fb130-8884-431b-936c-85e656e3e54f",
   "metadata": {},
   "source": [
    "# 3D Embedding data EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "408dfe29-acba-47a5-8eed-6814ac4e01df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4227590,3) into shape (4227588,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Populate the tensor\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, channel \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(eeg_channels):\n\u001b[0;32m---> 25\u001b[0m     \u001b[43meeg_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(extract_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3dembedded_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Saving path for the CNN tensor\u001b[39;00m\n\u001b[1;32m     28\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/3D_embedding_EEG_tensor.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (4227590,3) into shape (4227588,3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "eeg_channels = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6',\n",
    "                'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6',\n",
    "                'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
    "\n",
    "# Extract zip file\n",
    "zip_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/3dembedded_data.zip'\n",
    "extract_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Phase Space/3dembedding_data/temp'\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# Load the first channel to determine the number of data points\n",
    "first_channel_data = np.load(os.path.join(extract_path, f'3dembedded_{eeg_channels[0]}.npy'))\n",
    "num_data_points, emb_dim = first_channel_data.shape\n",
    "num_channels = len(eeg_channels)\n",
    "\n",
    "# Initialize a 4D tensor to store embeddings\n",
    "eeg_tensor = np.zeros((num_data_points, emb_dim, num_channels, 1))\n",
    "\n",
    "# Populate the tensor\n",
    "for idx, channel in enumerate(eeg_channels):\n",
    "    eeg_tensor[:, :, idx, 0] = np.load(os.path.join(extract_path, f'3dembedded_{channel}.npy'))\n",
    "\n",
    "# Saving path for the CNN tensor\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/3D_embedding_EEG_tensor.pth\"\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(eeg_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d94ef-b060-4166-8343-7c0313a0d0e2",
   "metadata": {},
   "source": [
    "# Hurst Exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81f444af-9c00-4732-b1f9-f0fceebc2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load Data\n",
    "hurst_exponents = np.load('/home/vincent/AAA_projects/MVCS/Neuroscience/HurstExponents/hurst_exponents.npy')\n",
    "\n",
    "# Reshape and normalize data\n",
    "hurst_exponents = hurst_exponents.reshape(-1, 1)  # Reshape to (num_channels, 1)\n",
    "normalized_data = (hurst_exponents - np.mean(hurst_exponents)) / np.std(hurst_exponents)\n",
    "\n",
    "# Convert to PyTorch tensor and reshape for CNN\n",
    "hurst_tensor = torch.tensor(normalized_data).float().unsqueeze(0).unsqueeze(1)  # Shape: (1, 1, num_channels, 1)\n",
    "\n",
    "# Saving path for the CNN tensor\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/Hurst_tensor.pth\"\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(hurst_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a162ef-7ead-423c-9011-6efba211a157",
   "metadata": {},
   "source": [
    "# MFDFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0008a928-641d-4e88-8c8a-d40e2bdeac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the saved numpy features\n",
    "cnn_features = np.load('/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/MFDFA/cnn_mfdfa.npy')\n",
    "\n",
    "# Reshape the Data to include a channel dimension\n",
    "cnn_features_tensor = cnn_features[..., np.newaxis]  # Adding a channel dimension\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "cnn_features_tensor_torch = torch.tensor(cnn_features_tensor, dtype=torch.float32)\n",
    "\n",
    "# Save the tensor using torch.save\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/mfdfa_tensor.pth\"\n",
    "torch.save(cnn_features_tensor_torch, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e585f6d9-b0a2-4def-a150-f771867d2bbf",
   "metadata": {},
   "source": [
    "# MFDFA Concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7a8da54-e20b-47a0-b2dc-b7dd47604d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the MFDFA results from the file\n",
    "save_dir = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/MFDFA/'  \n",
    "mfdfa_results_np = np.load(save_dir + 'MFDFA_results.npy', allow_pickle=True)\n",
    "\n",
    "# Extract the dictionary from the numpy scalar\n",
    "mfdfa_results = mfdfa_results_np.item()\n",
    "\n",
    "# Extract the channels data from your dictionary\n",
    "channels_data = [mfdfa_results[key] for key in sorted(mfdfa_results.keys())]\n",
    "\n",
    "# List to store the data for each channel\n",
    "channel_images = []\n",
    "\n",
    "for channel_data in channels_data:\n",
    "    scales, fluctuations = channel_data\n",
    "    # Reshape the scales and fluctuations into column vectors\n",
    "    scales = scales.reshape(-1, 1)\n",
    "    fluctuations = fluctuations.mean(axis=1).reshape(-1, 1)  # Take the mean of fluctuations across its scales for simplicity\n",
    "    \n",
    "    # Concatenate the scales and fluctuations horizontally to form an \"image\"\n",
    "    channel_image = np.hstack([scales, fluctuations])\n",
    "    channel_images.append(channel_image)\n",
    "\n",
    "# Convert the list of channel images to a tensor\n",
    "tensor = torch.from_numpy(np.array(channel_images)).float()\n",
    "\n",
    "# Reshape the tensor to [batch_size, channels, height, width]\n",
    "mfdfa_concatd_tensor = tensor.unsqueeze(1)  # Adding a channel dimension, assuming you want a single channel for each image\n",
    "\n",
    "# Save the tensor using torch.save\n",
    "save_path = \"/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/mfdfa_concatd_tensor.pth\"\n",
    "torch.save(mfdfa_concatd_tensor, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542deb9-5222-46c5-bc6b-62a2178a0152",
   "metadata": {},
   "source": [
    "# Arnold Tongues Rotation Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a42ab2d-ec8f-4048-9390-b3739ca5d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the saved rotation numbers\n",
    "rotation_numbers_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Arnold Tongues/rotation_numbers.npy'\n",
    "rotation_numbers_dict = np.load(rotation_numbers_path, allow_pickle=True).item()\n",
    "\n",
    "# EEG channels definition (as per your previous code)\n",
    "eeg_channels = ['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6',\n",
    "                'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6',\n",
    "                'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
    "\n",
    "# Omegas and K_values are derived from your earlier code\n",
    "omegas = np.linspace(0, 1, 300)\n",
    "K_values = np.linspace(0, 2 * np.pi, 300)\n",
    "\n",
    "tensor_shape = (len(eeg_channels), len(K_values), len(omegas))\n",
    "rotation_numbers_tensor = np.zeros(tensor_shape)\n",
    "\n",
    "for idx, ch in enumerate(eeg_channels):\n",
    "    rotation_numbers_tensor[idx] = rotation_numbers_dict[ch]\n",
    "\n",
    "# Convert the numpy tensor to a PyTorch tensor\n",
    "rotation_numbers_torch_tensor = torch.tensor(rotation_numbers_tensor)\n",
    "\n",
    "# Save the PyTorch tensor to disk\n",
    "torch_save_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Arnold Tongues/rotation_numbers_tensor.pt'\n",
    "torch.save(rotation_numbers_torch_tensor, torch_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48028b-eb8c-4a9b-b07d-9ed82a8ff8eb",
   "metadata": {},
   "source": [
    "# Transfer Entropy Hemispheric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f0fb6d5-3d16-4dbf-9bd7-0f2e40afc5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved CNN input data\n",
    "cnn_input_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Features/CNN/cnn_transfer_entropy_hemispheric_avg_input.npy'\n",
    "cnn_input_data = np.load(cnn_input_path)\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "cnn_input_tensor = torch.tensor(cnn_input_data)\n",
    "\n",
    "# Save the PyTorch tensor to disk\n",
    "torch_save_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/transfer_entropy_hemispheric_avg_input_tensor.pt'\n",
    "torch.save(cnn_input_tensor, torch_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ee6e9-6364-45de-b34b-3cd9207ee673",
   "metadata": {},
   "source": [
    "# Transfer Entropy Regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27ebdd4e-ff84-4cbd-a754-76661854427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.25110662 0.57730508 0.67410323]\n",
      " [0.33752969 0.         0.47118759 0.61260954]\n",
      " [0.38813154 0.22015982 0.         0.63537753]\n",
      " [0.42216949 0.28119128 0.58496923 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the saved CNN input data\n",
    "cnn_input_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Transfer Entropy/regional_transfer_entropy_results.npy'\n",
    "cnn_input_data = np.load(cnn_input_path, allow_pickle=True).item()\n",
    "\n",
    "regions = [\"Frontal\", \"Temporal\", \"Parietal\", \"Occipital\"]\n",
    "TE_matrix = np.zeros((4, 4))\n",
    "\n",
    "for i, source in enumerate(regions):\n",
    "    for j, target in enumerate(regions):\n",
    "        if i != j:\n",
    "            key = f\"{source}_to_{target}\"\n",
    "            TE_matrix[i, j] = cnn_input_data[key]\n",
    "\n",
    "print(TE_matrix)\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "cnn_input_tensor = torch.tensor(TE_matrix)\n",
    "\n",
    "# Save the PyTorch tensor to disk\n",
    "torch_save_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/transfer_entropy_regional_tensor.pt'\n",
    "torch.save(cnn_input_tensor, torch_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f41323-daa6-422a-ad74-b6a300e5448d",
   "metadata": {},
   "source": [
    "# Transfer Entropy Granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe473a78-fbee-4722-8e04-4f25ed022600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the numpy results file\n",
    "results_file_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Analysis/Transfer Entropy/regional_transfer_entropy_results.npy'\n",
    "TE_results = np.load(results_file_path, allow_pickle=True).item()\n",
    "\n",
    "# Define the brain regions\n",
    "regions = ['Frontal', 'Temporal', 'Parietal', 'Occipital']\n",
    "\n",
    "# Create a 4x4 matrix with zeros\n",
    "TE_matrix = np.zeros((4, 4))\n",
    "\n",
    "# Fill the matrix using the provided results\n",
    "for i, source_region in enumerate(regions):\n",
    "    for j, target_region in enumerate(regions):\n",
    "        if i != j:\n",
    "            key = f\"{source_region}_to_{target_region}\"\n",
    "            TE_matrix[i, j] = TE_results[key]\n",
    "\n",
    "# Convert the numpy matrix to PyTorch tensor\n",
    "TE_tensor = torch.tensor(TE_matrix)\n",
    "\n",
    "# Save the PyTorch tensor to disk\n",
    "torch_save_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/transfer_entropy_granular_tensor.pt'\n",
    "torch.save(TE_tensor, torch_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d678e-b564-4f66-9cf2-b536e02900d0",
   "metadata": {},
   "source": [
    "# Transfer Entropy add dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcf848-149d-4393-b40c-031ee5e7ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_entropy_granular_tensor = transfer_entropy_granular_tensor.unsqueeze(0).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493e4ae-6d84-4c09-9b46-7df14761c9ba",
   "metadata": {},
   "source": [
    "# DSPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22af4f8d-2f76-4541-97a9-00d6684c9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the numpy data\n",
    "cnn_data_np = np.load('/home/vincent/AAA_projects/MVCS/Neuroscience/Features/CNN/cnn_dspm.npy')\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "cnn_data_tensor = torch.tensor(cnn_data_np)\n",
    "\n",
    "# Save the tensor using PyTorch's save function\n",
    "torch.save(cnn_data_tensor, '/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/cnn_dspm_tensor.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735be0c-f5a8-4e10-bddd-9908f52ace17",
   "metadata": {},
   "source": [
    "# Higuchi Fractal Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7b65de8-de61-415f-a64e-facf3bf1ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load the CNN feature\n",
    "cnn_features_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Features/CNN/cnn_fractal.npy'\n",
    "cnn_features = np.load(cnn_features_path)\n",
    "\n",
    "# Reshape for CNN (batch_size, channels, height, width)\n",
    "cnn_tensor = torch.tensor(cnn_features).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Save the PyTorch tensor to disk\n",
    "torch_save_path = '/home/vincent/AAA_projects/MVCS/Neuroscience/Models/CNN/higuchi_fractal_dimensions_tensor.pt'\n",
    "torch.save(cnn_tensor, torch_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14940ed-617c-4044-8e2a-d7c9a13ce29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
